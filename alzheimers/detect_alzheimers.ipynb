{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data/oasis_longitudinal.csv\"\n",
    "df = pd.read_csv(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>MRI ID</th>\n",
       "      <th>Group</th>\n",
       "      <th>Visit</th>\n",
       "      <th>MR Delay</th>\n",
       "      <th>M/F</th>\n",
       "      <th>Hand</th>\n",
       "      <th>Age</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>SES</th>\n",
       "      <th>MMSE</th>\n",
       "      <th>CDR</th>\n",
       "      <th>eTIV</th>\n",
       "      <th>nWBV</th>\n",
       "      <th>ASF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0.696</td>\n",
       "      <td>0.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>OAS2_0001</td>\n",
       "      <td>OAS2_0001_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>457</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.681</td>\n",
       "      <td>0.876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>OAS2_0004</td>\n",
       "      <td>OAS2_0004_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>88</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1215</td>\n",
       "      <td>0.710</td>\n",
       "      <td>1.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>OAS2_0004</td>\n",
       "      <td>OAS2_0004_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>538</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>90</td>\n",
       "      <td>18</td>\n",
       "      <td>3.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1200</td>\n",
       "      <td>0.718</td>\n",
       "      <td>1.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>OAS2_0005</td>\n",
       "      <td>OAS2_0005_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>80</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1689</td>\n",
       "      <td>0.712</td>\n",
       "      <td>1.039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>OAS2_0005</td>\n",
       "      <td>OAS2_0005_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>1010</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>83</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1701</td>\n",
       "      <td>0.711</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>OAS2_0005</td>\n",
       "      <td>OAS2_0005_MR3</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>3</td>\n",
       "      <td>1603</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1699</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>OAS2_0008</td>\n",
       "      <td>OAS2_0008_MR1</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>93</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1272</td>\n",
       "      <td>0.698</td>\n",
       "      <td>1.380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>OAS2_0008</td>\n",
       "      <td>OAS2_0008_MR2</td>\n",
       "      <td>Nondemented</td>\n",
       "      <td>2</td>\n",
       "      <td>742</td>\n",
       "      <td>F</td>\n",
       "      <td>R</td>\n",
       "      <td>95</td>\n",
       "      <td>14</td>\n",
       "      <td>2.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1257</td>\n",
       "      <td>0.703</td>\n",
       "      <td>1.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>OAS2_0009</td>\n",
       "      <td>OAS2_0009_MR1</td>\n",
       "      <td>Demented</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>M</td>\n",
       "      <td>R</td>\n",
       "      <td>68</td>\n",
       "      <td>12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1457</td>\n",
       "      <td>0.806</td>\n",
       "      <td>1.205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject ID         MRI ID        Group  Visit  MR Delay M/F Hand  Age  \\\n",
       "0   OAS2_0001  OAS2_0001_MR1  Nondemented      1         0   M    R   87   \n",
       "1   OAS2_0001  OAS2_0001_MR2  Nondemented      2       457   M    R   88   \n",
       "5   OAS2_0004  OAS2_0004_MR1  Nondemented      1         0   F    R   88   \n",
       "6   OAS2_0004  OAS2_0004_MR2  Nondemented      2       538   F    R   90   \n",
       "7   OAS2_0005  OAS2_0005_MR1  Nondemented      1         0   M    R   80   \n",
       "8   OAS2_0005  OAS2_0005_MR2  Nondemented      2      1010   M    R   83   \n",
       "9   OAS2_0005  OAS2_0005_MR3  Nondemented      3      1603   M    R   85   \n",
       "13  OAS2_0008  OAS2_0008_MR1  Nondemented      1         0   F    R   93   \n",
       "14  OAS2_0008  OAS2_0008_MR2  Nondemented      2       742   F    R   95   \n",
       "15  OAS2_0009  OAS2_0009_MR1     Demented      1         0   M    R   68   \n",
       "\n",
       "    EDUC  SES  MMSE  CDR  eTIV   nWBV    ASF  \n",
       "0     14  2.0  27.0  0.0  1987  0.696  0.883  \n",
       "1     14  2.0  30.0  0.0  2004  0.681  0.876  \n",
       "5     18  3.0  28.0  0.0  1215  0.710  1.444  \n",
       "6     18  3.0  27.0  0.0  1200  0.718  1.462  \n",
       "7     12  4.0  28.0  0.0  1689  0.712  1.039  \n",
       "8     12  4.0  29.0  0.5  1701  0.711  1.032  \n",
       "9     12  4.0  30.0  0.0  1699  0.705  1.033  \n",
       "13    14  2.0  30.0  0.0  1272  0.698  1.380  \n",
       "14    14  2.0  29.0  0.0  1257  0.703  1.396  \n",
       "15    12  2.0  27.0  0.5  1457  0.806  1.205  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Definition\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "class AlzheimersDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.df = pd.read_csv(root_dir)\n",
    "        cols_to_drop = ['Visit', 'Subject ID', 'MRI ID', 'Hand', 'M/F']\n",
    "        self.df = self.df.dropna(axis=0)\n",
    "        self.df = self.df.drop(cols_to_drop, axis=1)\n",
    "        labels = [1 if group == 'Demented' else 0 for group in self.df.Group]\n",
    "        self.df.Group = labels\n",
    "        self.data = self.df.to_numpy()\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i]\n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(batch):\n",
    "    label = [entry[0] for entry in batch]\n",
    "    inputs = [entry[1:] for entry in batch]\n",
    "    return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset length: 318 | test_dataset length: 36\n"
     ]
    }
   ],
   "source": [
    "alzh_data = AlzheimersDataset(DATA_DIR)\n",
    "train_len = int(len(alzh_data) * 0.9) # 10% Split\n",
    "train_dataset, test_dataset = random_split(alzh_data, \\\n",
    "                                           [train_len, \\\n",
    "                                            len(alzh_data) - train_len\n",
    "                                           ])\n",
    "print(\"train_dataset length: {0} | test_dataset length: {1}\".format(len(train_dataset), \\\n",
    "                                                                 len(test_dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "from sklearn.svm import SVC\n",
    "def train_SVM(x, y, params):\n",
    "    clf = SVC(**params)\n",
    "    clf.fit(x, y)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_params = {\n",
    "    'C': 1,\n",
    "    'kernel': 'poly',\n",
    "    'gamma': 'auto',\n",
    "    'degree': 2\n",
    "}\n",
    "train_x, train_y = generate_batch(train_dataset)\n",
    "test_x, test_y = generate_batch(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = train_SVM(train_x, train_y, svm_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_score: 0.95%, test_score: 0.97%\n",
      "fpr: 1.00%, fnr: 1.00%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "def get_error_rates(clf, x, y_true):\n",
    "    y_pred = clf.predict(x)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "#     print(cm)\n",
    "    tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "    fpr = fp/(fp+tn)\n",
    "    fnr = fn/(tp+fn)\n",
    "    return fpr, fnr, cm\n",
    "    \n",
    "fpr_svm, fnr_svm, cm_svm = get_error_rates(clf, train_x, train_y)\n",
    "print(\"train_score: {0:.2f}%, test_score: {1:.2f}%\".format(clf.score(train_x, train_y), \\\n",
    "                                                clf.score(test_x, test_y)))\n",
    "print('fpr: {0:.2f}%, fnr: {0:.2f}%'.format( \\\n",
    "                                           fpr_svm, fnr_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction using Linear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Nondemented\n",
      "Actual: Nondemented\n"
     ]
    }
   ],
   "source": [
    "labels = {\n",
    "    1:'Demented',\n",
    "    0:'Nondemented'\n",
    "}\n",
    "idx = 60\n",
    "prediction = clf.predict(np.array([alzh_data[idx, 1:]]))\n",
    "print(\"Predicted: {}\".format(labels[int(prediction)]))\n",
    "print(\"Actual: {}\".format(labels[alzh_data[idx, 0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Linear NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models\n",
    "# - SVM\n",
    "# - Linear NN\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlzheimersNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_size, embed_dim)\n",
    "        self.linear = nn.Linear(embed_dim, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        initrange = 0.5\n",
    "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear.bias.data.zero_()\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        embeds = self.embedding(inp)\n",
    "        out = self.linear(embeds)\n",
    "#         out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch_tensor(batch):\n",
    "    label = torch.tensor([entry[0] for entry in batch])\n",
    "    inputs = torch.tensor([entry[1:] for entry in batch]).long()\n",
    "    return inputs, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func(sub_train_):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    data = DataLoader(sub_train_, batch_size=BATCH_SIZE, shuffle=True, \\\n",
    "                      collate_fn=generate_batch_tensor)\n",
    "    for i, (inputs, label) in enumerate(data):\n",
    "        optimizer.zero_grad()\n",
    "        inputs, label = inputs.to(device), label.to(device)\n",
    "        \n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, label)\n",
    "        train_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_acc += (output.argmax(1) == label).sum().item()\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    return train_loss / len(sub_train_), train_acc / len(sub_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# BATCH_SIZE = 4\n",
    "# EMBED_DIM = 16\n",
    "# N_EPOCHS = 5\n",
    "\n",
    "# train_losses = []\n",
    "# valid_losses = []\n",
    "\n",
    "# model = AlzheimersNN(10, EMBED_DIM).to(device)\n",
    "# criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=4.0)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
    "\n",
    "# train_len = int(len(train_dataset) * 0.95)\n",
    "# sub_train_, sub_valid = \\\n",
    "#     random_split(train_dataset, [train_len, len(train_dataset) - train_len])\n",
    "# print(\"Training on {}\".format(device))\n",
    "\n",
    "# for epoch in range(N_EPOCHS):\n",
    "\n",
    "#     start_time = time.time()\n",
    "#     train_loss, train_acc = train_func(sub_train_)\n",
    "#     valid_loss, valid_acc = test(sub_valid)\n",
    "#     train_losses.append(train_loss)\n",
    "#     val_losses.append(valid_loss)\n",
    "#     secs = int(time.time() - start_time)\n",
    "#     mins = secs / 60\n",
    "#     secs = secs % 60\n",
    "\n",
    "#     print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n",
    "#     print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n",
    "#     print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')\n",
    "\n",
    "# torch.save(model, \"saved_models/linear_nn.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
